version: '3'
networks:
  pulsar:
    driver: bridge
  ingestion_net:
    driver: bridge
  auditoria_net:
    driver: bridge
  canonization_net:
    driver: bridge
services:
  # Start zookeeper
  zookeeper:
    image: apachepulsar/pulsar:latest
    container_name: zookeeper
    restart: on-failure
    networks:
      - pulsar
    volumes:
      - ./data/zookeeper:/pulsar/data/zookeeper
    environment:
      - metadataStoreUrl=zk:zookeeper:2181
    command: >
      bash -c "bin/apply-config-from-env.py conf/zookeeper.conf && \
             bin/generate-zookeeper-config.sh conf/zookeeper.conf && \
             exec bin/pulsar zookeeper"
    healthcheck:
      test: [ "CMD", "bin/pulsar-zookeeper-ruok.sh" ]
      interval: 10s
      timeout: 5s
      retries: 30

  # Init cluster metadata
  pulsar-init:
    container_name: pulsar-init
    hostname: pulsar-init
    image: apachepulsar/pulsar:latest
    networks:
      - pulsar
    command: >
      bin/pulsar initialize-cluster-metadata --cluster cluster-a --zookeeper zookeeper:2181 --configuration-store zookeeper:2181 --web-service-url http://broker:8080 --broker-service-url pulsar://broker:6650
    depends_on:
      zookeeper:
        condition: service_healthy

  # Start bookie
  bookie:
    image: apachepulsar/pulsar:latest
    container_name: bookie
    restart: on-failure
    networks:
      - pulsar
    environment:
      - clusterName=cluster-a
      - zkServers=zookeeper:2181
      - metadataServiceUri=metadata-store:zk:zookeeper:2181
      # otherwise every time we run docker compose uo or down we fail to start due to Cookie
      # See: https://github.com/apache/bookkeeper/blob/405e72acf42bb1104296447ea8840d805094c787/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Cookie.java#L57-68
      - advertisedAddress=bookie
      - BOOKIE_MEM=-Xms512m -Xmx512m -XX:MaxDirectMemorySize=256m
    depends_on:
      zookeeper:
        condition: service_healthy
      pulsar-init:
        condition: service_completed_successfully
    # Map the local directory to the container to avoid bookie startup failure due to insufficient container disks.
    volumes:
      - ./data/bookkeeper:/pulsar/data/bookkeeper
    command: >
      bash -c "bin/apply-config-from-env.py conf/bookkeeper.conf && exec bin/pulsar bookie"

  # Start broker
  broker:
    image: apachepulsar/pulsar:latest
    container_name: broker
    hostname: broker
    restart: on-failure
    networks:
      - pulsar
    environment:
      - metadataStoreUrl=zk:zookeeper:2181
      - zookeeperServers=zookeeper:2181
      - clusterName=cluster-a
      - managedLedgerDefaultEnsembleSize=1
      - managedLedgerDefaultWriteQuorum=1
      - managedLedgerDefaultAckQuorum=1
      - advertisedAddress=broker
      - advertisedListeners=local:pulsar://broker:6650,external:pulsar://127.0.0.1:6650
      - PULSAR_MEM=-Xms512m -Xmx512m -XX:MaxDirectMemorySize=256m
      - isAllowAutoUpdateSchema=true
    depends_on:
      zookeeper:
        condition: service_healthy
      bookie:
        condition: service_started
    command: bash -c "bin/apply-config-from-env.py conf/broker.conf && exec bin/pulsar broker"
    healthcheck:
      test: [ "CMD-SHELL", "bin/pulsar-admin brokers list cluster-a" ]
      interval: 10s
      timeout: 5s
      retries: 5
  ingestion:
    build: ./src/ingestion
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    container_name: ingestion-container
    environment:
      - DB_USER=ingestion
      - DB_PASSWORD=admin
      - DB_HOST=ingestion_db
      - DB_PORT=5432
      - DB_NAME=postgres_ingestion_db
      - PULSAR_BROKER_URL=pulsar://broker:6650
      - REDIS_HOST=ingestion_redis
      - REDIS_PORT=6379
    networks:
      - pulsar
      - ingestion_net
    depends_on:
      ingestion_db:
        condition: service_healthy
      broker:
        condition: service_healthy
      ingestion_redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    restart: on-failure
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8000/ingestion/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
  ingestion_consumer:
    build: ./src/ingestion
    command: python -u start_consumers.py
    container_name: ingestion-consumer-container
    environment:
      - DB_USER=ingestion
      - DB_PASSWORD=admin
      - DB_HOST=ingestion_db
      - DB_PORT=5432
      - DB_NAME=postgres_ingestion_db
      - PULSAR_BROKER_URL=pulsar://broker:6650
      - REDIS_HOST=ingestion_redis
      - REDIS_PORT=6379
    networks:
      - pulsar
      - ingestion_net
    depends_on:
      ingestion_db:
        condition: service_healthy
      broker:
        condition: service_healthy
      ingestion:
        condition: service_healthy
      ingestion_redis:
        condition: service_healthy
    restart: on-failure
  ingestion_db:
    image: postgres:latest
    container_name: ingestion_db
    environment:
      - POSTGRES_USER=ingestion
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=postgres_ingestion_db
    networks:
      - ingestion_net
    restart: on-failure
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}" ]
      interval: 10s
      timeout: 5s
      retries: 5
  ingestion_worker:
    build: ./src/ingestion
    command: celery -A celery_worker worker --loglevel=info
    container_name: ingestion-worker-container
    environment:
      - DB_USER=ingestion
      - DB_PASSWORD=admin
      - DB_HOST=ingestion_db
      - DB_PORT=5432
      - DB_NAME=postgres_ingestion_db
      - PULSAR_BROKER_URL=pulsar://broker:6650
      - REDIS_HOST=ingestion_redis
      - REDIS_PORT=6379
    networks:
      - pulsar
      - ingestion_net
    depends_on:
      ingestion_db:
        condition: service_healthy
      broker:
        condition: service_healthy
      ingestion_redis:
        condition: service_healthy
    restart: on-failure
  ingestion_redis:
    image: redis:latest
    container_name: ingestion_redis
    networks:
      - ingestion_net
    restart: on-failure
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

  anonimizacion:
    build: ./src/anonimizacion
    container_name: anonimizacion-container
    command: uvicorn api.main:app --host 0.0.0.0 --port 8001
    environment:
      - BROKER_HOST=broker
    networks:
      - pulsar
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - "8001:8001"

  # consumidor:
  #   build: ./src/consumidor
  #   container_name: consumidor-container
  #   environment:
  #     - BROKER_HOST=broker
  #   networks:
  #     - pulsar
  #   depends_on:
  #     broker:
  #       condition: service_healthy
  #   restart: on-failure

  # Servicio de Auditoria
  auditoria:
    build: ./src/auditoria
    container_name: auditoria-container
    command: flask --app api run --host=0.0.0.0 --port=8002 --debugger
    working_dir: /app
    environment:
      - BROKER_HOST=broker
      - DB_USERNAME=auditoria
      - DB_PASSWORD=admin
      - DB_HOSTNAME=auditoria_db
      - DB_NAME=postgres_auditoria_db
      - PULSAR_BROKER_URL=pulsar://broker:6650
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    networks:
      - pulsar
      - auditoria_net
    depends_on:
      auditoria_db:
        condition: service_healthy
      broker:
        condition: service_healthy
    ports:
      - "8002:8002"
  auditoria_db:
    image: postgres:latest
    container_name: auditoria_db
    environment:
      - POSTGRES_USER=auditoria
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=postgres_auditoria_db
    restart: on-failure
    networks:
      - auditoria_net
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}" ]
      interval: 10s
      timeout: 5s
      retries: 5

  canonization:
    build: ./src/canonization
    command: uvicorn main:app --host 0.0.0.0 --port 8005
    container_name: canonization-container
    environment:
      - DB_USER=canonization
      - DB_PASSWORD=admin
      - DB_HOST=canonization_db
      - DB_PORT=5432
      - DB_NAME=postgres_canonization_db
      - PULSAR_BROKER_URL=pulsar://broker:6650
      - REDIS_HOST=canonization_redis
      - REDIS_PORT=6379
    networks:
      - pulsar
      - canonization_net
    depends_on:
      canonization_db:
        condition: service_healthy
      broker:
        condition: service_healthy
      canonization_redis:
        condition: service_healthy
    ports:
      - "8005:8005"
    restart: on-failure
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8005/canonization/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
  canonization_consumer:
    build: ./src/canonization
    command: python -u start_consumers.py
    container_name: canonization-consumer-container
    environment:
      - DB_USER=canonization
      - DB_PASSWORD=admin
      - DB_HOST=canonization_db
      - DB_PORT=5432
      - DB_NAME=postgres_canonization_db
      - PULSAR_BROKER_URL=pulsar://broker:6650
      - REDIS_HOST=canonization_redis
      - REDIS_PORT=6379
    networks:
      - pulsar
      - canonization_net
    depends_on:
      canonization_db:
        condition: service_healthy
      broker:
        condition: service_healthy
      canonization:
        condition: service_healthy
      canonization_redis:
        condition: service_healthy
    restart: on-failure
  canonization_db:
    image: postgres:latest
    container_name: canonization_db
    environment:
      - POSTGRES_USER=canonization
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=postgres_canonization_db
    networks:
      - canonization_net
    restart: on-failure
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}" ]
      interval: 10s
      timeout: 5s
      retries: 5
  canonization_worker:
    build: ./src/canonization
    command: celery -A celery_worker worker --loglevel=info
    container_name: canonization-worker-container
    environment:
      - DB_USER=canonization
      - DB_PASSWORD=admin
      - DB_HOST=canonization_db
      - DB_PORT=5432
      - DB_NAME=postgres_canonization_db
      - PULSAR_BROKER_URL=pulsar://broker:6650
      - REDIS_HOST=canonization_redis
      - REDIS_PORT=6379
    networks:
      - pulsar
      - canonization_net
    depends_on:
      canonization_db:
        condition: service_healthy
      broker:
        condition: service_healthy
      canonization_redis:
        condition: service_healthy
    restart: on-failure
  canonization_redis:
    image: redis:latest
    container_name: canonization_redis
    networks:
      - canonization_net
    restart: on-failure
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
  # Standalone Pulsar
  pulsar-standalone:
    image: apachepulsar/pulsar:latest
    container_name: pulsar-standalone
    restart: on-failure
    networks:
      - pulsar
    ports:
      - "6650:6650"
      - "8080:8080"
    command: bin/pulsar standalone -nfw
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/admin/v2/brokers/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
  bff:
     build: ./src/bff_web
     container_name: bff-container
     command: uvicorn main:app --host 0.0.0.0 --port 8006  --reload
     working_dir: /app
     environment:
       - INGESTION_PATH=http://ingestion:8000
       - CANONIZATION_PATH=http://canonization:8005
       - AUDIT_PATH=http://auditoria:8002
       - PYTHONPATH=/app
       - PYTHONUNBUFFERED=1
     networks:
       - ingestion_net
       - auditoria_net
       - canonization_net
     ports:
       - "8006:8006"